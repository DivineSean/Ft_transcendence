groups:
  - name: system-alerts
    rules:
      # High CPU Usage
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[1m])) * 100) > 90
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is above 90% for 2 minutes on {{ $labels.instance }} (current value: {{ $value }}%)"

      # High Memory Usage
      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is above 85% for 2 minutes on {{ $labels.instance }} (current value: {{ $value }}%)"

      # Low Disk Space
      - alert: LowDiskSpace
        expr: node_filesystem_free_bytes / node_filesystem_size_bytes * 100 < 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Less than 10% disk space is free on {{ $labels.mountpoint }} (current value: {{ $value }}%)"

      # High Network Traffic
      - alert: HighNetworkTraffic
        expr: rate(node_network_receive_bytes_total[1m]) > 100000000 or rate(node_network_transmit_bytes_total[1m]) > 100000000
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "High network traffic on {{ $labels.instance }}"
          description: "Network traffic exceeds 100MB/s on {{ $labels.device }} (current value: {{ $value }})"

  - name: application-alerts
    rules:
      # High Response Latency (HTTP/NGINX Services)
      - alert: HighHTTPResponseLatency
        expr: rate(http_server_request_duration_seconds_sum[1m]) / rate(http_server_request_duration_seconds_count[1m]) > 0.5
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "High response latency on {{ $labels.instance }}"
          description: "Average response latency exceeds 500ms (current value: {{ $value }}s)"

      # NGINX 5xx Errors
      - alert: NGINX5xxErrors
        expr: rate(nginx_http_response_count_total{status=~"5.."}[1m]) > 10
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High NGINX 5xx error rate on {{ $labels.instance }}"
          description: "NGINX is serving more than 10 5xx errors per minute (current value: {{ $value }})"

  - name: service-health-alerts
    rules:
      # Service Down
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Service is down on {{ $labels.instance }}"
          description: "The {{ $labels.job }} service is down on {{ $labels.instance }}"

      # Redis Down
      - alert: RedisServiceDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Redis service is down on {{ $labels.instance }}"
          description: "The Redis service is not responding on {{ $labels.instance }}."

      # PostgresDown
      - alert: PostgreSQLServiceDown
        expr: pg_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "PostgreSQL service is down on {{ $labels.instance }}"
          description: "The PostgreSQL service is not responding on {{ $labels.instance }}."

      # Database Connection Errors (PostgreSQL)
      - alert: DatabaseConnectionErrors
        expr: rate(pg_stat_activity_count{state='idle in transaction aborted'}[5m]) > 5
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Database connection errors on {{ $labels.instance }}"
          description: "More than 5 aborted connections in the past 5 minutes (current value: {{ $value }})"

      # Prometheus Target Down
      - alert: PrometheusTargetDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Prometheus target down on {{ $labels.instance }}"
          description: "The target {{ $labels.job }} is down on {{ $labels.instance }}"
